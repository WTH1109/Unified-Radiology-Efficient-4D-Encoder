# UMEé¡¹ç›®é‡å¤§ä¿®æ­£ï¼šæ­£ç¡®å®ç°VoCoè®­ç»ƒ

## ğŸ”§ ä¿®æ­£æ¦‚è¦

åŸºäºç”¨æˆ·åé¦ˆï¼Œé¡¹ç›®å·²ä»é”™è¯¯çš„"å¸§çº§é‡‡æ ·è®­ç»ƒ"ä¿®æ­£ä¸ºæ­£ç¡®çš„"VoCoè‡ªç›‘ç£è®­ç»ƒ"æ–¹å¼ã€‚

## âŒ ä¹‹å‰çš„é”™è¯¯è®¾è®¡

1. **é”™è¯¯çš„æ•°æ®è¯»å–**: åœ¨æ•°æ®åŠ è½½æ—¶å°±é‡‡æ ·å¸§ï¼Œè¯»å…¥çš„æ˜¯(256,256,8)è€Œä¸æ˜¯å®Œæ•´æ•°æ®
2. **é”™è¯¯çš„ç›‘ç£ä¿¡å·**: ä½¿ç”¨åˆ†å‰²æ ‡ç­¾ä½œä¸ºç›‘ç£
3. **é”™è¯¯çš„è®­ç»ƒæ–¹å¼**: ä¼ ç»Ÿçš„ç›‘ç£å­¦ä¹ è€Œä¸æ˜¯è‡ªç›‘ç£å­¦ä¹ 

## âœ… æ­£ç¡®çš„VoCoè®¾è®¡

### 1. å®Œæ•´æ•°æ®è¯»å–
- **ä¿®æ”¹å‰**: æ•°æ®åŠ è½½æ—¶é‡‡æ ·â†’(256,256,8)
- **ä¿®æ”¹å**: å®Œæ•´è¯»å–â†’(256,256,128)ï¼Œäº¤ç»™æ™ºèƒ½å…³é”®å¸§é€‰æ‹©ç½‘ç»œ

### 2. VoCoè‡ªç›‘ç£è®­ç»ƒ
- **æ ¸å¿ƒæ€æƒ³**: éšæœºé€‰æ‹©ä¸€ä¸ªcropï¼Œè®¡ç®—ä¸4ä¸ªç›¸äº¤cropçš„é¢ç§¯æ¯”ä½œä¸ºç›‘ç£
- **æ— éœ€æ ‡ç­¾**: çº¯è‡ªç›‘ç£ï¼Œä¸ä¾èµ–åˆ†å‰²æ ‡æ³¨
- **å¯¹æ¯”å­¦ä¹ **: åŸºäºç›¸äº¤ç¨‹åº¦è¿›è¡Œç‰¹å¾å¯¹æ¯”å­¦ä¹ 

### 3. æ™ºèƒ½å…³é”®å¸§é€‰æ‹©
- **ç½‘ç»œå†…å¤„ç†**: å®Œæ•´æ•°æ®è¾“å…¥â†’å…³é”®å¸§é€‰æ‹©ç½‘ç»œâ†’æ™ºèƒ½é‡‡æ ·
- **å¤šç­–ç•¥èåˆ**: å‡åŒ€+å†…å®¹æ„ŸçŸ¥+æ³¨æ„åŠ›å¼•å¯¼

## ğŸ”„ ä¸»è¦ä»£ç ä¿®æ”¹

### 1. æ•°æ®åŠ è½½å™¨ (`ume/data/brats_loader.py`)
```python
# ç§»é™¤äº†UMEFrameSamplingdå˜æ¢
# ä¿æŒå®Œæ•´çš„128å¸§ï¼Œäº¤ç»™å…³é”®å¸§é€‰æ‹©ç½‘ç»œå¤„ç†
```

### 2. VoCoç›‘ç£å®ç° (`ume/utils/voco_supervision.py`)
- `VoCoSupervision`: ç”Ÿæˆéšæœºcropå’Œç›¸äº¤é¢ç§¯æ¯”
- `VoCoLoss`: åŸºäºé¢ç§¯æ¯”çš„å¯¹æ¯”å­¦ä¹ æŸå¤±
- `VoCoAugmentation`: VoCoæ•°æ®å¢å¼º

### 3. æ¨¡å‹æ¶æ„ (`ume/models/ume_model.py`)
```python
def forward(self, x, mode='training'):
    if mode == 'voco_training':
        return self._voco_forward(x)  # VoCoè®­ç»ƒæ¨¡å¼
    else:
        return self._standard_forward(x, mode)  # ä¼ ç»Ÿæ¨¡å¼
```

### 4. æŸå¤±å‡½æ•° (`ume/utils/losses.py`)
```python
# æ–°å¢VoCoæ¨¡å¼æ”¯æŒ
def __init__(self, use_voco=False):
    if use_voco:
        self.voco_loss = VoCoLoss()
```

### 5. è®­ç»ƒè„šæœ¬ (`ume/training/train_ume.py`)
```python
# VoCoè®­ç»ƒæ¨¡å¼
outputs = self.model(images, mode='voco_training')
loss_dict = self.criterion(
    main_features=outputs.get('main_features'),
    neighbor_features=outputs.get('neighbor_features'),
    overlap_areas=outputs.get('overlap_areas')
)
```

## ğŸ“ æ–°å¢é…ç½®æ–‡ä»¶

### VoCoè®­ç»ƒé…ç½® (`configs/brats_ume_voco.json`)
```json
{
  "training": {
    "loss_weights": {
      "voco": 1.0,
      "diversity": 0.1,
      "contrastive": 0.5,
      "area": 0.3
    }
  },
  "voco": {
    "crop_size": [64, 64, 32],
    "overlap_ratio": 0.25,
    "temperature": 0.07
  }
}
```

## ğŸš€ ä½¿ç”¨æ–¹å¼

### VoCoè‡ªç›‘ç£è®­ç»ƒï¼ˆæ¨èï¼‰
```bash
python ume/training/train_ume.py --config configs/brats_ume_voco.json
```

### ä¼ ç»Ÿåˆ†å‰²è®­ç»ƒï¼ˆå¯¹æ¯”ï¼‰
```bash
python ume/training/train_ume.py --config configs/brats_ume_config.json
```

## ğŸ“Š è®­ç»ƒæŒ‡æ ‡å¯¹æ¯”

### VoCoè®­ç»ƒæŒ‡æ ‡
```
Training Epoch 0: loss=1.8245, voco=1.2150, div=0.1895, area=0.4200
```
- **voco**: VoCoå¯¹æ¯”å­¦ä¹ æŸå¤±
- **area**: é¢ç§¯é¢„æµ‹æŸå¤±

### ä¼ ç»Ÿè®­ç»ƒæŒ‡æ ‡
```
Training Epoch 0: loss=2.2136, div=0.7695, seg=2.1366
```
- **seg**: åˆ†å‰²æŸå¤±

## ğŸ¯ æŠ€æœ¯ä¼˜åŠ¿

1. **è‡ªç›‘ç£å­¦ä¹ **: æ— éœ€äººå·¥æ ‡æ³¨ï¼Œé™ä½æ•°æ®ä¾èµ–
2. **å®Œæ•´æ•°æ®åˆ©ç”¨**: å……åˆ†åˆ©ç”¨128å¸§çš„å®Œæ•´ä¿¡æ¯
3. **æ™ºèƒ½é‡‡æ ·**: ç½‘ç»œå­¦ä¹ æœ€ä¼˜çš„å…³é”®å¸§é€‰æ‹©ç­–ç•¥
4. **å¯¹æ¯”å­¦ä¹ **: åŸºäºç©ºé—´ç›¸å…³æ€§çš„ç‰¹å¾å­¦ä¹ 

## âš ï¸ é‡è¦æé†’

- **æ¨èä½¿ç”¨VoCoè®­ç»ƒ**: è¿™æ˜¯é¡¹ç›®çš„æ ¸å¿ƒåˆ›æ–°ç‚¹
- **å®Œæ•´æ•°æ®è¾“å…¥**: ç¡®ä¿è¾“å…¥æ˜¯(256,256,128)è€Œä¸æ˜¯é‡‡æ ·åçš„æ•°æ®
- **é…ç½®æ–‡ä»¶é€‰æ‹©**: ä½¿ç”¨`brats_ume_voco.json`è¿›è¡ŒVoCoè®­ç»ƒ

ä¿®æ­£åçš„é¡¹ç›®ç°åœ¨æ­£ç¡®å®ç°äº†VoCoè‡ªç›‘ç£è®­ç»ƒï¼Œç¬¦åˆåŸå§‹è®¾è®¡æ„å›¾ï¼ğŸ‰